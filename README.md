# LendingClub Loan Default Prediction: Supervised Learning vs Offline RL

This project implements and compares two approaches to loan approval decisions:
1. **Supervised Learning**: Deep learning model (MLP) predicting default probability
2. **Offline Reinforcement Learning**: CQL / Q-agent learning optimal approval policy

**Author**: Mayank Jyani  
**Date**: December 2025

## Project Overview

This repository contains the code, data processing, notebooks and reports used for the Shodh AI assignment on policy optimization for loan approvals. The goal is to compare a supervised predictive model and an offline RL policy that directly optimizes monetary reward.

## Corrected Repository Layout (actual files present)
Below is the corrected layout reflecting files currently in the repository. If you add/remove files, update this section.

```
shodh-loan-project/
├── data/                                 # Raw and processed data (place raw CSV here)
│   ├── accepted_2007_to_2018.csv         # (download from Kaggle) — optional, large
│   ├── processed/                        # generated by preprocessing scripts (parquet)
│   └── rl/                               # generated RL artifacts (npz, feature_cols.csv)
├── src/                                  # Source code & notebooks (scripts executed)
│   ├── eda_notebook.ipynb                # EDA notebook (active file edited)
│   ├── bootstrap_policy_test.py          # Bootstrap CI script (present)
│   ├── 00_download_and_sample.py         # (optional) data sampling/download helper
│   ├── 01_preprocess.py                  # preprocessing pipeline (if present)
│   ├── 02_dataset.py                     # dataset / dataloader utilities (if present)
│   ├── 03_train_supervised.py            # supervised training script (if present)
│   ├── 04_eval_supervised.py             # supervised evaluation script (if present)
│   ├── 05_convert_for_rl.py              # convert data to RL format (if present)
│   ├── 06_train_offline_rl.py            # offline RL training script (if present)
│   ├── 07_eval_rl.py                     # RL evaluation script (if present)
│   └── demo_predict.py                   # small demo to predict one applicant (if present)
├── models/                               # Trained model artifacts (generated)
│   ├── best_model.pth                    # Supervised checkpoint (if produced)
│   └── rl_q/                             # RL model artifacts and predictions
│       ├── q_agent_best.pth
│       └── q_agent_test_predictions.csv
├── reports/
│   ├── final_report.md                   # Final report (markdown)
│   ├── final_report.pdf                  # Final report (PDF) — may be generated locally
│   └── figures/                          # Figures generated by notebooks
│       ├── target_balance_train.png
│       ├── numeric_feature_histograms.png
│       ├── corr_heatmap.png
│       ├── reward_and_approve_rate.png
│       ├── shap_supervised_summary.png   # if SHAP ran
│       └── shap_qagent_summary.png       # if SHAP ran
├── notebooks/                            # Optional additional notebooks
│   └── (other .ipynb files)
├── requirements.txt                      # Python dependencies
└── README.md                             # This file
```

Notes:
- The layout lists core files actually present (eda_notebook.ipynb and bootstrap_policy_test.py are in src/).
- Several scripts listed under src/ are optional placeholders — keep or remove based on your repo contents.
- Ensure large raw CSVs are not committed to Git (store locally or reference download instructions).

## Quickstart — Setup & Run

1. Create and activate virtual environment:
```powershell
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt
```

2. Place `accepted_2007_to_2018.csv` in `data/` or use the downloader if present:
```powershell
cd src
python 00_download_and_sample.py --input ../data/accepted_2007_to_2018.csv --sample-size 200000
```

3. Run the pipeline (example order):
```powershell
cd src
python 01_preprocess.py
python 03_train_supervised.py --epochs 30 --batch-size 512
python 04_eval_supervised.py
python 05_convert_for_rl.py
python 06_train_offline_rl.py --n-epochs 50
python 07_eval_rl.py
python bootstrap_policy_test.py
```

## Artifacts & Outputs

- Supervised model: `models/best_model.pth`, evaluation plots under `reports/figures/`
- RL model: `models/rl_q/q_agent_best.pth`, predictions `models/rl_q/q_agent_test_predictions.csv`
- Bootstrap results: `models/rl_q/bootstrap_rl_minus_sup.csv`
- Final report: `reports/final_report.md` and optional `reports/final_report.pdf`


# End of README
