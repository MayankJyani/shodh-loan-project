{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d811cad",
   "metadata": {},
   "source": [
    "# EDA — Processed data, predictions and RL datasets\n",
    "\n",
    "Quick exploratory analysis for: data splits, target balance, feature distributions, reward distribution, and policy comparisons (historical / BC / RL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c355bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths:\n",
      " processed: C:\\Users\\mayan\\OneDrive\\Desktop\\New folder\\shodh-loan-project\\data\\processed\n",
      " rl npz:   C:\\Users\\mayan\\OneDrive\\Desktop\\New folder\\shodh-loan-project\\data\\rl\n",
      " models:   C:\\Users\\mayan\\OneDrive\\Desktop\\New folder\\shodh-loan-project\\models\n",
      " output figs: C:\\Users\\mayan\\OneDrive\\Desktop\\New folder\\shodh-loan-project\\reports\\figures\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "DATA_DIR = Path('../data/processed')\n",
    "RL_DIR = Path('../data/rl')\n",
    "MODELS_DIR = Path('../models')\n",
    "REPORT_DIR = Path('../reports/figures')\n",
    "REPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Paths:')\n",
    "print(' processed:', DATA_DIR.resolve())\n",
    "print(' rl npz:  ', RL_DIR.resolve())\n",
    "print(' models:  ', MODELS_DIR.resolve())\n",
    "print(' output figs:', REPORT_DIR.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "115d3cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_cols.csv found at ..\\data\\rl\\feature_cols.csv\n",
      "--- file preview (first 1k chars) ---\n",
      " 0\n",
      "total_acc\n",
      "installment\n",
      "home_ownership\n",
      "pub_rec\n",
      "income_to_loan\n",
      "pub_rec_bankruptcies\n",
      "purpose\n",
      "verification_status\n",
      "sub_grade\n",
      "term\n",
      "grade\n",
      "emp_length_years\n",
      "dti\n",
      "open_acc\n",
      "revol_bal\n",
      "annual_inc\n",
      "revol_util\n",
      "installment_to_income\n",
      "fico_range_low\n",
      "inq_last_6mths\n",
      "credit_utilization\n",
      "fico_score\n",
      "delinq_2yrs\n",
      "term_months\n",
      "addr_state\n",
      "mort_acc\n",
      "emp_length\n",
      "fico_range_high\n",
      "\n",
      "Read as single-column list (first 20): ['0', 'total_acc', 'installment', 'home_ownership', 'pub_rec', 'income_to_loan', 'pub_rec_bankruptcies', 'purpose', 'verification_status', 'sub_grade', 'term', 'grade', 'emp_length_years', 'dti', 'open_acc', 'revol_bal', 'annual_inc', 'revol_util', 'installment_to_income', 'fico_range_low']\n",
      "Final feature_cols (n=28). Sample: ['total_acc', 'installment', 'home_ownership', 'pub_rec', 'income_to_loan', 'pub_rec_bankruptcies', 'purpose', 'verification_status', 'sub_grade', 'term', 'grade', 'emp_length_years', 'dti', 'open_acc', 'revol_bal', 'annual_inc', 'revol_util', 'installment_to_income', 'fico_range_low', 'inq_last_6mths']\n"
     ]
    }
   ],
   "source": [
    "# Robust feature_cols loading / debug\n",
    "train = pd.read_parquet(DATA_DIR / 'train.parquet').reset_index(drop=True)\n",
    "val = pd.read_parquet(DATA_DIR / 'val.parquet').reset_index(drop=True)\n",
    "test = pd.read_parquet(DATA_DIR / 'test.parquet').reset_index(drop=True)\n",
    "\n",
    "exclude = {'target', 'loan_amnt', 'int_rate', 'id', 'index'}\n",
    "fpath = RL_DIR / 'feature_cols.csv'\n",
    "\n",
    "if fpath.exists():\n",
    "    print('feature_cols.csv found at', fpath)\n",
    "    txt = fpath.read_text(errors='ignore')\n",
    "    print('--- file preview (first 1k chars) ---\\n', txt[:1000])\n",
    "    try:\n",
    "        fc = pd.read_csv(fpath, header=None).iloc[:,0].astype(str).tolist()\n",
    "        print('Read as single-column list (first 20):', fc[:20])\n",
    "    except Exception:\n",
    "        try:\n",
    "            df_fc = pd.read_csv(fpath)\n",
    "            fc = df_fc.columns.tolist()\n",
    "            print('Read header columns (first 20):', fc[:20])\n",
    "        except Exception as e:\n",
    "            print('Failed to read feature file:', e)\n",
    "            fc = []\n",
    "    # keep only valid columns that exist in the dataframe and not in exclude\n",
    "    feature_cols = [c for c in fc if (c in train.columns) and (c not in exclude)]\n",
    "    if not feature_cols:\n",
    "        # try interpreting numeric strings as indices into train.columns\n",
    "        idxs = []\n",
    "        for x in fc:\n",
    "            try:\n",
    "                idxs.append(int(x))\n",
    "            except Exception:\n",
    "                pass\n",
    "        if idxs:\n",
    "            cols = list(train.columns)\n",
    "            feature_cols = [cols[i] for i in idxs if 0 <= i < len(cols) and cols[i] not in exclude]\n",
    "    if not feature_cols:\n",
    "        print('feature_cols from file invalid or empty — falling back to automatic detection')\n",
    "        feature_cols = [c for c in train.columns if c not in exclude]\n",
    "else:\n",
    "    feature_cols = [c for c in train.columns if c not in exclude]\n",
    "\n",
    "print('Final feature_cols (n=%d). Sample:' % len(feature_cols), feature_cols[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "554ebe86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      " {0: 115250, 1: 28750}  ({0: 80.03, 1: 19.97})\n",
      "val:\n",
      " {0: 12806, 1: 3194}  ({0: 80.04, 1: 19.96})\n",
      "test:\n",
      " {0: 32014, 1: 7986}  ({0: 80.04, 1: 19.96})\n",
      "Saved target balance plot to ..\\reports\\figures\\target_balance_train.png\n"
     ]
    }
   ],
   "source": [
    "# Target / class balance\n",
    "for name, df in [('train', train), ('val', val), ('test', test)]:\n",
    "    counts = df['target'].value_counts().sort_index()\n",
    "    pct = 100 * counts / counts.sum()\n",
    "    print(f\"{name}:\\n {counts.to_dict()}  ({pct.round(2).to_dict()})\")\n",
    "\n",
    "# save simple chart\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "sns.barplot(x=['fully_paid','default'], y=[(train['target']==0).mean(), (train['target']==1).mean()])\n",
    "ax.set_ylabel('Proportion (train)')\n",
    "fig.tight_layout()\n",
    "fig.savefig(REPORT_DIR / 'target_balance_train.png', dpi=150)\n",
    "plt.close(fig)\n",
    "print('Saved target balance plot to', REPORT_DIR / 'target_balance_train.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59f5596c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'0'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mayan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: '0'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Numeric feature distributions (select up to 6 numeric features)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m num_cols = [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m feature_cols \u001b[38;5;28;01mif\u001b[39;00m pd.api.types.is_numeric_dtype(\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m)] \n\u001b[32m      3\u001b[39m sample_cols = num_cols[:\u001b[32m6\u001b[39m]\n\u001b[32m      4\u001b[39m fig, axes = plt.subplots(\u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, figsize=(\u001b[32m14\u001b[39m,\u001b[32m8\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mayan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mayan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: '0'"
     ]
    }
   ],
   "source": [
    "# Numeric feature distributions (select up to 6 numeric features)\n",
    "num_cols = [c for c in feature_cols if pd.api.types.is_numeric_dtype(train[c])] \n",
    "sample_cols = num_cols[:6]\n",
    "fig, axes = plt.subplots(2, 3, figsize=(14,8))\n",
    "for ax, col in zip(axes.flatten(), sample_cols):\n",
    "    sns.histplot(train[col].dropna(), bins=50, ax=ax, kde=False)\n",
    "    ax.set_title(col)\n",
    "fig.tight_layout()\n",
    "fig.savefig(REPORT_DIR / 'numeric_feature_histograms.png', dpi=150)\n",
    "plt.close(fig)\n",
    "print('Saved numeric histograms to', REPORT_DIR / 'numeric_feature_histograms.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2dbd2d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Correlation heatmap for numeric features (subset to speed up)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m corr_cols = \u001b[43mnum_cols\u001b[49m[:\u001b[32m12\u001b[39m]\n\u001b[32m      3\u001b[39m corr = train[corr_cols].corr()\n\u001b[32m      4\u001b[39m fig, ax = plt.subplots(figsize=(\u001b[32m10\u001b[39m,\u001b[32m8\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'num_cols' is not defined"
     ]
    }
   ],
   "source": [
    "# Correlation heatmap for numeric features (subset to speed up)\n",
    "corr_cols = num_cols[:12]\n",
    "corr = train[corr_cols].corr()\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "sns.heatmap(corr, annot=False, cmap='coolwarm', center=0, ax=ax)\n",
    "fig.tight_layout()\n",
    "fig.savefig(REPORT_DIR / 'corr_heatmap.png', dpi=150)\n",
    "plt.close(fig)\n",
    "print('Saved correlation heatmap to', REPORT_DIR / 'corr_heatmap.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2a75b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved reward + approve-rate plot to ..\\reports\\figures\\reward_and_approve_rate.png\n"
     ]
    }
   ],
   "source": [
    "# Reward distribution and approve rates (using RL npz and model preds if available)\n",
    "rl_npz = np.load(RL_DIR / 'test_rl.npz')\n",
    "rewards = rl_npz['rewards']\n",
    "fig, ax = plt.subplots(1,2, figsize=(12,4))\n",
    "sns.histplot(rewards, bins=80, ax=ax[0])\n",
    "ax[0].set_title('Reward distribution (test)')\n",
    "ax[0].set_xlabel('reward')\n",
    "\n",
    "# Load predictions if present\n",
    "preds_path = MODELS_DIR / 'test_predictions.csv'\n",
    "df_preds = pd.read_csv(preds_path) if preds_path.exists() else None\n",
    "if df_preds is not None:\n",
    "    approve_rate = df_preds.filter(regex='pred_label').iloc[:,0].mean()\n",
    "else:\n",
    "    approve_rate = None\n",
    "ax[1].bar(['approve_rate'], [approve_rate if approve_rate is not None else np.nan])\n",
    "ax[1].set_ylim(0,1)\n",
    "ax[1].set_title('Sample approve rate (from preds)')\n",
    "fig.tight_layout()\n",
    "fig.savefig(REPORT_DIR / 'reward_and_approve_rate.png', dpi=150)\n",
    "plt.close(fig)\n",
    "print('Saved reward + approve-rate plot to', REPORT_DIR / 'reward_and_approve_rate.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fbf11b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved policy comparison CSV to ..\\reports\\figures\\policy_comparison.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>historical_avg_reward</th>\n",
       "      <td>-0.026583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>historical_approve_rate</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>supervised_avg_reward</th>\n",
       "      <td>-0.039507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>supervised_approve_rate</th>\n",
       "      <td>0.426850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rl_avg_reward</th>\n",
       "      <td>0.042508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rl_approve_rate</th>\n",
       "      <td>0.610700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0\n",
       "historical_avg_reward   -0.026583\n",
       "historical_approve_rate  1.000000\n",
       "supervised_avg_reward   -0.039507\n",
       "supervised_approve_rate  0.426850\n",
       "rl_avg_reward            0.042508\n",
       "rl_approve_rate          0.610700"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare policies: historical (from data), supervised (test_predictions.csv), BC (if available), RL (q_agent preds)\n",
    "results = {}\n",
    "n = len(rewards)\n",
    "\n",
    "# historical policy: actions column if present in processed data (fallback: all approved)\n",
    "if 'is_approved' in test.columns:\n",
    "    hist_actions = test['is_approved'].astype(int).values\n",
    "else:\n",
    "    hist_actions = np.ones(n, dtype=int)\n",
    "results['historical_avg_reward'] = (rewards * (hist_actions==1)).mean()\n",
    "results['historical_approve_rate'] = hist_actions.mean()\n",
    "\n",
    "if df_preds is not None:\n",
    "    # choose pred_label_optimal if present else 0.5\n",
    "    if 'pred_label_optimal' in df_preds.columns:\n",
    "        sup_actions = df_preds['pred_label_optimal'].astype(int).values\n",
    "    elif 'pred_label_0.5' in df_preds.columns:\n",
    "        sup_actions = df_preds['pred_label_0.5'].astype(int).values\n",
    "    else:\n",
    "        sup_actions = (df_preds['pred_proba'] >= 0.5).astype(int).values\n",
    "    results['supervised_avg_reward'] = (rewards * (sup_actions==1)).mean()\n",
    "    results['supervised_approve_rate'] = sup_actions.mean()\n",
    "else:\n",
    "    results['supervised_avg_reward'] = np.nan\n",
    "    results['supervised_approve_rate'] = np.nan\n",
    "\n",
    "# RL Q-agent preds\n",
    "q_preds_path = MODELS_DIR / 'rl_q' / 'q_agent_test_predictions.csv'\n",
    "if q_preds_path.exists():\n",
    "    q_df = pd.read_csv(q_preds_path)\n",
    "    q_actions = q_df['action'].astype(int).values\n",
    "    results['rl_avg_reward'] = (rewards * (q_actions==1)).mean()\n",
    "    results['rl_approve_rate'] = q_actions.mean()\n",
    "else:\n",
    "    results['rl_avg_reward'] = np.nan\n",
    "    results['rl_approve_rate'] = np.nan\n",
    "\n",
    "pd.DataFrame([results]).T.rename(columns={0:'value'})\n",
    "pd.DataFrame([results]).T.to_csv(REPORT_DIR / 'policy_comparison.csv')\n",
    "print('Saved policy comparison CSV to', REPORT_DIR / 'policy_comparison.csv')\n",
    "pd.DataFrame([results]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b107b7",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "- Inspect feature importance / model explanations (SHAP) for supervised model and RL Q-network.\n",
    "- Tune reward function and retrain RL agent or train conservative objective.\n",
    "- Add more EDA plots if you want (e.g., approval rate vs. credit score bins, PD vs. loan amount).\n",
    "\n",
    "If you want, I can extend this notebook with more specific plots — tell me which figures you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90f2f608",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['0'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m REPORT_DIR = Path(\u001b[33m'\u001b[39m\u001b[33m../reports/figures\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     13\u001b[39m REPORT_DIR.mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m X = \u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m]\u001b[49m.fillna(\u001b[32m0\u001b[39m).astype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[32m     16\u001b[39m X_test = test[feature_cols].fillna(\u001b[32m0\u001b[39m).astype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[32m     17\u001b[39m sample_n = \u001b[38;5;28mmin\u001b[39m(\u001b[32m500\u001b[39m, \u001b[38;5;28mlen\u001b[39m(X_test))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mayan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mayan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mayan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['0'] not in index\""
     ]
    }
   ],
   "source": [
    "# Add this cell after the \"Next steps\" markdown (adds SHAP explanations for supervised model and Q-agent)\n",
    "try:\n",
    "    import shap\n",
    "except Exception:\n",
    "    print(\"shap not installed. Install: pip install shap\")\n",
    "else:\n",
    "    import torch\n",
    "    import matplotlib.pyplot as plt\n",
    "    from dataset import MLPClassifier\n",
    "    from pathlib import Path\n",
    "\n",
    "    REPORT_DIR = Path('../reports/figures')\n",
    "    REPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    X = train[feature_cols].fillna(0).astype(float)\n",
    "    X_test = test[feature_cols].fillna(0).astype(float)\n",
    "    sample_n = min(500, len(X_test))\n",
    "    idx = np.random.RandomState(42).choice(len(X_test), sample_n, replace=False)\n",
    "    X_back = X.sample(n=min(200, len(X)), random_state=42).values  # background for explainer\n",
    "    X_samp = X_test.iloc[idx].values\n",
    "\n",
    "    # Supervised model SHAP (probability of default -> use prob of default or paid)\n",
    "    sup_ckpt_path = Path('../models/best_model.pth')\n",
    "    if sup_ckpt_path.exists():\n",
    "        try:\n",
    "            ckpt = torch.load(sup_ckpt_path, map_location='cpu')\n",
    "            input_dim = ckpt.get('input_dim', X.shape[1])\n",
    "            hidden_dims = ckpt.get('hidden_dims', [256,128,64])\n",
    "            dropout = ckpt.get('dropout', 0.3)\n",
    "            sup_model = MLPClassifier(input_dim, hidden_dims, dropout)\n",
    "            sup_model.load_state_dict(ckpt['model_state_dict'])\n",
    "            sup_model.eval()\n",
    "\n",
    "            def sup_predict_prob(x):\n",
    "                with torch.no_grad():\n",
    "                    t = torch.from_numpy(np.asarray(x, dtype=np.float32))\n",
    "                    logits = sup_model(t)\n",
    "                    probs = torch.sigmoid(logits).numpy().flatten()\n",
    "                    return np.vstack([1 - probs, probs]).T  # shape (N,2)\n",
    "\n",
    "            explainer = shap.Explainer(sup_predict_prob, X_back, feature_names=feature_cols)\n",
    "            shap_vals = explainer(X_samp)\n",
    "            plt.figure(figsize=(8,6))\n",
    "            shap.summary_plot(shap_vals, features=pd.DataFrame(X_samp, columns=feature_cols), show=False)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(REPORT_DIR / 'shap_supervised_summary.png', dpi=150)\n",
    "            plt.close()\n",
    "            print(\"Saved supervised SHAP summary to\", REPORT_DIR / 'shap_supervised_summary.png')\n",
    "        except Exception as e:\n",
    "            print(\"Supervised SHAP failed:\", e)\n",
    "    else:\n",
    "        print(\"Supervised model checkpoint not found at\", sup_ckpt_path)\n",
    "\n",
    "    # Q-agent SHAP (prob approve = softmax(Q)[1])\n",
    "    q_ckpt_path = Path('../models/rl_q/q_agent_best.pth')\n",
    "    if q_ckpt_path.exists():\n",
    "        try:\n",
    "            # define simple QNetwork matching training script\n",
    "            import torch.nn as nn\n",
    "            class QNetwork(nn.Module):\n",
    "                def __init__(self, input_dim, hidden_dims=(256,128)):\n",
    "                    super().__init__()\n",
    "                    layers = []\n",
    "                    prev = input_dim\n",
    "                    for h in hidden_dims:\n",
    "                        layers.append(nn.Linear(prev, h))\n",
    "                        layers.append(nn.ReLU())\n",
    "                        prev = h\n",
    "                    layers.append(nn.Linear(prev, 2))\n",
    "                    self.net = nn.Sequential(*layers)\n",
    "                def forward(self, x):\n",
    "                    return self.net(x)\n",
    "\n",
    "            q_ckpt = torch.load(q_ckpt_path, map_location='cpu')\n",
    "            q_input = int(q_ckpt.get('input_dim', X.shape[1]))\n",
    "            q_hidden = tuple(q_ckpt.get('hidden_dims', [256,128]))\n",
    "            q_model = QNetwork(q_input, q_hidden)\n",
    "            q_model.load_state_dict(q_ckpt['model_state_dict'])\n",
    "            q_model.eval()\n",
    "\n",
    "            def q_predict_prob(x):\n",
    "                with torch.no_grad():\n",
    "                    t = torch.from_numpy(np.asarray(x, dtype=np.float32))\n",
    "                    qvals = q_model(t).numpy()\n",
    "                    # softmax to get action probabilities\n",
    "                    exp = np.exp(qvals - np.max(qvals, axis=1, keepdims=True))\n",
    "                    probs = exp / exp.sum(axis=1, keepdims=True)\n",
    "                    return probs  # shape (N,2)\n",
    "\n",
    "            expl = shap.Explainer(q_predict_prob, X_back, feature_names=feature_cols)\n",
    "            shap_vals_q = expl(X_samp)\n",
    "            plt.figure(figsize=(8,6))\n",
    "            shap.summary_plot(shap_vals_q, features=pd.DataFrame(X_samp, columns=feature_cols), show=False)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(REPORT_DIR / 'shap_qagent_summary.png', dpi=150)\n",
    "            plt.close()\n",
    "            print(\"Saved Q-agent SHAP summary to\", REPORT_DIR / 'shap_qagent_summary.png')\n",
    "        except Exception as e:\n",
    "            print(\"Q-agent SHAP failed:\", e)\n",
    "    else:\n",
    "        print(\"Q-agent checkpoint not found at\", q_ckpt_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
